using System;
using System.Collections.Generic;
using System.Linq;
using System.Text;
using System.Threading.Tasks;
using RimTalk.Data;
using RimTalk.Error;
using RimTalk.Util;
using UnityEngine.Networking;
using Verse;

namespace RimTalk.Client.OpenAI;

public class OpenAIClient(
    string baseUrl,
    string model,
    string apiKey = null,
    Dictionary<string, string> extraHeaders = null)
    : IAIClient
{
    private const string DefaultPath = "/v1/chat/completions";
    private readonly string _endpointUrl = FormatEndpointUrl(baseUrl);
    private static UnityWebRequest _currentRequest;
    private static readonly object _requestLock = new object();
    
    public static void AbortCurrentRequest()
    {
        lock (_requestLock)
        {
            if (_currentRequest != null)
            {
                Logger.Debug("Aborting current AI request");
                _currentRequest.Abort();
                _currentRequest = null;
            }
        }
    }

    private static string FormatEndpointUrl(string baseUrl)
    {
        if (string.IsNullOrEmpty(baseUrl)) return string.Empty;
        var trimmed = baseUrl.Trim().TrimEnd('/');
        var uri = new Uri(trimmed);
        // Append default path if only base domain is provided
        return (uri.AbsolutePath == "/" || string.IsNullOrEmpty(uri.AbsolutePath.Trim('/')))
            ? trimmed + DefaultPath
            : trimmed;
    }

    public async Task<Payload> GetChatCompletionAsync(List<(Role role, string message)> prefixMessages, 
        List<(Role role, string message)> messages, 
        Action<Payload> onRequestPrepared = null)
    {
        string jsonContent = BuildRequestJson(prefixMessages, messages, stream: false);
        onRequestPrepared?.Invoke(new Payload(_endpointUrl, model, jsonContent, null, 0));
        string responseText = await SendRequestAsync(jsonContent, new DownloadHandlerBuffer());

        var response = JsonUtil.DeserializeFromJson<OpenAIResponse>(responseText);
        var content = response?.Choices?[0]?.Message?.Content;
        var tokens = response?.Usage?.TotalTokens ?? 0;

        return new Payload(_endpointUrl, model, jsonContent, content, tokens);
    }

    public async Task<Payload> GetStreamingChatCompletionAsync<T>(List<(Role role, string message)> prefixMessages,
        List<(Role role, string message)> messages, 
        Action<T> onResponseParsed,
        Action<Payload> onRequestPrepared = null) where T : class
    {
        string jsonContent = BuildRequestJson(prefixMessages, messages, stream: true);
        onRequestPrepared?.Invoke(new Payload(_endpointUrl, model, jsonContent, null, 0));
        var jsonParser = new JsonStreamParser<T>();

        var streamHandler = new OpenAIStreamHandler(chunk =>
        {
            foreach (var response in jsonParser.Parse(chunk))
                onResponseParsed?.Invoke(response);
        });
        
        await SendRequestAsync(jsonContent, streamHandler);

        return new Payload(_endpointUrl, model, jsonContent, streamHandler.GetFullText(),
            streamHandler.GetTotalTokens());
    }

    private string BuildRequestJson(List<(Role role, string message)> prefixMessages, List<(Role role, string message)> messages, bool stream)
    {
        var allMessages = new List<Message>();
        
        // Add prefix messages with their original roles
        if (prefixMessages != null)
        {
            allMessages.AddRange(prefixMessages.Select(m => new Message
            {
                Role = RoleToString(m.role),
                Content = m.message
            }));
        }

        // Add conversation messages
        allMessages.AddRange(messages.Select(m => new Message
        {
            Role = RoleToString(m.role),
            Content = m.message
        }));


        var setting = Settings.Get();
        var request = new OpenAIRequest
        {
            Model = model,
            Messages = allMessages,
            Temperature = setting.OpenAITemperature,
            TopP = setting.OpenAITopP,
            FrequencyPenalty = setting.OpenAIFrequencyPenalty,
            PresencePenalty = setting.OpenAIPresencePenalty,

            Stream = stream,
            StreamOptions = stream ? new StreamOptions { IncludeUsage = true } : null,
            // ResponseFormat = new Dictionary<string, string> {{"type", "json_object"}}
        };

        return JsonUtil.SerializeToJson(request);
    }

    private static string RoleToString(Role role)
    {
        return role switch
        {
            Role.System => "system",
            Role.User => "user",
            Role.AI => "assistant",
            _ => "user"
        };
    }

    private async Task<string> SendRequestAsync(string jsonContent, DownloadHandler downloadHandler)
    {
        if (string.IsNullOrEmpty(_endpointUrl))
        {
            Logger.Error("Endpoint URL is missing.");
            return null;
        }

        Logger.Debug($"API request: {_endpointUrl}\n{jsonContent}");

        UnityWebRequest webRequest = null;
        try
        {
            webRequest = new UnityWebRequest(_endpointUrl, "POST");
            webRequest.uploadHandler = new UploadHandlerRaw(Encoding.UTF8.GetBytes(jsonContent));
            webRequest.downloadHandler = downloadHandler;
            webRequest.SetRequestHeader("Content-Type", "application/json");
            
            lock (_requestLock)
            {
                _currentRequest = webRequest;
            }

            if (!string.IsNullOrEmpty(apiKey))
                webRequest.SetRequestHeader("Authorization", $"Bearer {apiKey}");

            if (extraHeaders != null)
            {
                foreach (var header in extraHeaders)
                    webRequest.SetRequestHeader(header.Key, header.Value);
            }

            var asyncOp = webRequest.SendWebRequest();

            // Determine if target is local
            bool isLocal = _endpointUrl.Contains("localhost") || _endpointUrl.Contains("127.0.0.1") ||
                           _endpointUrl.Contains("192.168.") || _endpointUrl.Contains("10.");

            while (!asyncOp.isDone)
            {
                try
                {
                    await Task.Delay(100);
                }
                catch (Exception ex)
                {
                    Logger.Warning($"Task.Delay exception: {ex.Message}");
                    webRequest?.Abort();
                    throw;
                }
            }

            string responseText = downloadHandler.text;

        // Recover text for streaming errors
        if ((webRequest.responseCode >= 400 || webRequest.result == UnityWebRequest.Result.ConnectionError || webRequest.result == UnityWebRequest.Result.ProtocolError) &&
            downloadHandler is OpenAIStreamHandler sHandler)
        {
            responseText = sHandler.GetAllReceivedText();
            if (string.IsNullOrEmpty(responseText)) responseText = sHandler.GetRawJson();
        }

        if (webRequest.responseCode == 429)
        {
            string errorMsg = ErrorUtil.ExtractErrorMessage(responseText) ?? "Quota exceeded";
            throw new QuotaExceededException(errorMsg,
                new Payload(_endpointUrl, model, jsonContent, responseText, 0, errorMsg));
        }

        if (webRequest.result == UnityWebRequest.Result.ConnectionError || webRequest.result == UnityWebRequest.Result.ProtocolError)
        {
            string errorMsg = ErrorUtil.ExtractErrorMessage(responseText) ?? webRequest.error;
            Logger.Error($"Request failed: {webRequest.responseCode} - {errorMsg}");
            throw new AIRequestException(errorMsg,
                new Payload(_endpointUrl, model, jsonContent, responseText, 0, errorMsg));
        }

            if (downloadHandler is DownloadHandlerBuffer)
                Logger.Debug($"API response: \n{responseText}");
            else if (downloadHandler is OpenAIStreamHandler sh)
                Logger.Debug($"API response: \n{sh.GetRawJson()}");

            return responseText;
        }
        catch (Exception ex)
        {
            // Ensure request is aborted on any exception
            webRequest?.Abort();
            Logger.Error($"SendRequestAsync exception: {ex.Message}");
            throw;
        }
        finally
        {
            // Ensure proper cleanup
            lock (_requestLock)
            {
                if (_currentRequest == webRequest)
                {
                    _currentRequest = null;
                }
            }
            webRequest?.Dispose();
        }
    }

    public static async Task<List<string>> FetchModelsAsync(string apiKey, string url)
    {
        using var webRequest = UnityWebRequest.Get(url);
        webRequest.SetRequestHeader("Authorization", "Bearer " + apiKey);

        var asyncOp = webRequest.SendWebRequest();
        while (!asyncOp.isDone) await Task.Delay(100);

        if (webRequest.result == UnityWebRequest.Result.ConnectionError || webRequest.result == UnityWebRequest.Result.ProtocolError)
        {
            Logger.Error($"Failed to fetch models: {webRequest.error}");
            return new List<string>();
        }

        var response = JsonUtil.DeserializeFromJson<OpenAIModelsResponse>(webRequest.downloadHandler.text);
        return response?.Data?.Select(m => m.Id).ToList() ?? new List<string>();
    }
}
